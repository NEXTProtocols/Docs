---
title: 'Dataset'
description: 'Create training datasets from images with captions'
---

## Endpoint

```
POST /toolskit/dataset
```

## Description

Creates a training dataset from a collection of images with captions. The endpoint uploads images to S3, creates a ZIP archive containing the dataset, and stores metadata in Supabase.

## Authentication

Requires Bearer token authentication with the main API token.

## Request Body

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `user_id` | `string` | Yes | User identifier |
| `subject` | `string` | Yes | Dataset subject/topic |
| `name` | `string` | Yes | Dataset name |
| `gender` | `string` | Yes | Subject gender (`man` or `woman`) |
| `resolution` | `array` | Yes | Target resolutions |
| `dataset_content` | `array` | Yes | Array of images with captions |

### Dataset Content Object

| Field | Type | Description |
|-------|------|-------------|
| `picture_base64` | `string` | Base64 encoded image |
| `caption` | `string` | Caption/description for the image |

## Example Request

<CodeGroup>
```bash curl
curl -X POST http://localhost:8000/toolskit/dataset \
  -H "Authorization: Bearer YOUR_API_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user-123",
    "subject": "portrait",
    "name": "john_doe",
    "gender": "man",
    "resolution": ["512x512", "1024x1024"],
    "dataset_content": [
      {
        "picture_base64": "/9j/4AAQSkZJRgABAQAAAQABAAD...",
        "caption": "A man with short brown hair, smiling"
      },
      {
        "picture_base64": "/9j/4AAQSkZJRgABAQAAAQABAAD...",
        "caption": "A man in professional attire, neutral expression"
      }
    ]
  }'
```

```python python
import requests
import base64
from pathlib import Path

# Prepare dataset content
dataset_content = []
images_dir = Path("training_images")

for i, image_path in enumerate(images_dir.glob("*.jpg")):
    with open(image_path, "rb") as f:
        image_base64 = base64.b64encode(f.read()).decode()

    # Read caption from corresponding .txt file
    caption_path = image_path.with_suffix(".txt")
    caption = caption_path.read_text() if caption_path.exists() else ""

    dataset_content.append({
        "picture_base64": image_base64,
        "caption": caption
    })

response = requests.post(
    "http://localhost:8000/toolskit/dataset",
    headers={
        "Authorization": "Bearer YOUR_API_TOKEN",
        "Content-Type": "application/json"
    },
    json={
        "user_id": "user-123",
        "subject": "portrait",
        "name": "john_doe",
        "gender": "man",
        "resolution": ["512x512", "1024x1024"],
        "dataset_content": dataset_content
    }
)
print(response.json())
```
</CodeGroup>

## Response

### Success Response (200)

```json
{
  "message": "Dataset created"
}
```

### Error Responses

**Empty Dataset (400)**

```json
{
  "detail": "dataset_content is empty"
}
```

**Missing Picture (400)**

```json
{
  "detail": "dataset_content[0].picture_base64 is missing"
}
```

**Missing Caption (400)**

```json
{
  "detail": "dataset_content[0].caption is missing"
}
```

**Invalid Base64 (400)**

```json
{
  "detail": "Invalid base64 for dataset_content[0]"
}
```

## Process Flow

1. **Validation** - Validates all images have base64 and caption fields
2. **Image Processing** - Decodes and detects format for each image
3. **S3 Upload** - Uploads each image to S3 with organized path
4. **ZIP Creation** - Creates ZIP archive with images and caption text files
5. **Database Insert** - Stores metadata in `toolskit-training-dataset` table

## ZIP Structure

The generated ZIP file contains:

```
dataset.zip
├── 1.jpg          # First image
├── 1.txt          # First caption
├── 2.png          # Second image
├── 2.txt          # Second caption
└── ...
```

## S3 Storage Path

Images are stored at:

```
toolskit/dataset/{user_id}/{gender}/{name}/{subject}/{index}.{ext}
```

ZIP archive is stored at:

```
toolskit/dataset/{user_id}/{gender}/{name}/{subject}/dataset.zip
```

## Database Record

The endpoint creates a record in `toolskit-training-dataset` with:

| Field | Description |
|-------|-------------|
| `user_id` | User identifier |
| `name` | Dataset name |
| `gender` | Subject gender |
| `subject` | Dataset subject |
| `resolution` | Target resolutions array |
| `url_zip_all_pictures` | Public URL to ZIP archive |
| `all_pictures` | Array of `{picture_url, caption}` objects |

## Notes

- Images are 1-indexed in the ZIP (1.jpg, 2.jpg, etc.)
- Supported image formats: JPEG, PNG, WebP, GIF (auto-detected)
- Data URL prefixes are automatically stripped from base64
- The ZIP is compressed using DEFLATE algorithm
